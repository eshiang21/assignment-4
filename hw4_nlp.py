# -*- coding: utf-8 -*-
"""HW4_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pyd6zM_c8d0iKTiVuKSxvu8h2RDbLgOH

# Applied Machine Learning Homework 4
Due 12/15/21 11:59PM EST

### Q1: Natural Language Processing

We will train a supervised training model to predict if a tweet has a positive or negative sentiment.

#### Dataset loading & dev/test splits

1.1) Load the twitter dataset from NLTK library
"""

import nltk
nltk.download('twitter_samples')
from nltk.corpus import twitter_samples

"""1.2) Load the positive & negative tweets"""

all_positive_tweets = twitter_samples.strings('positive_tweets.json')
all_negative_tweets = twitter_samples.strings('negative_tweets.json')

"""1.3) Create a development & test split (80/20 ratio):"""

#code here
import pandas as pd
from sklearn.model_selection import train_test_split
df = pd.DataFrame({'review':all_positive_tweets + all_negative_tweets})
y = ['positive']*5000 + ['negative']*5000
dev_text, test_text, dev_y, test_y = train_test_split(df, y, test_size = 0.2, random_state = 0)

"""#### Data preprocessing

We will do some data preprocessing before we tokenize the data. We will remove `#` symbol, hyperlinks, stop words & punctuations from the data. You can use the `re` package in python to find and replace these strings.

1.4) Replace the `#` symbol with '' in every tweet
"""

#code here
dev_text['review'] = dev_text['review'].apply(lambda x: x.replace("#", '"'))
test_text['review'] = test_text['review'].apply(lambda x: x.replace("#", '"'))
dev_text[['#' in review for review in dev_text.review]].head()

"""1.5) Replace hyperlinks with '' in every tweet"""

#code here
import re
dev_text['review'] = dev_text['review'].apply(lambda x: re.sub(r'http\S+', '', x))
test_text['review'] = test_text['review'].apply(lambda x: re.sub(r'http\S+', '', x))
dev_text[['http' in review for review in dev_text.review]].head()

"""1.6) Remove all stop words"""

#code here
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

stop_words = set(ENGLISH_STOP_WORDS)
 
def remove_stop_words(sentence):
  return (" ").join([word for word in sentence.split(' ') if word.lower() not in stop_words])

dev_text['review'] = dev_text['review'].apply(lambda x: remove_stop_words(x))
test_text['review'] = test_text['review'].apply(lambda x: remove_stop_words(x))
dev_text.head()

"""1.7) Remove all punctuations"""

#code here
import string
punct = set(string.punctuation)

def remove_punct(sentence):
  return ''.join(ch for ch in sentence if ch not in punct)

dev_text['review'] = dev_text['review'].apply(lambda x: remove_punct(x))
test_text['review'] = test_text['review'].apply(lambda x: remove_punct(x))
dev_text.head()

"""1.8) Apply stemming on the development & test datasets using Porter algorithm"""

#code here
import nltk
nltk.download('punkt')

from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.stem import PorterStemmer

porter = PorterStemmer()

def stem_sentence(sentence):
  token_words = word_tokenize(sentence)
  stem_sentence = [porter.stem(word) for word in token_words]
  return " ".join(stem_sentence)

dev_text['review'] = dev_text['review'].apply(lambda x: stem_sentence(x))
test_text['review'] = test_text['review'].apply(lambda x: stem_sentence(x))
dev_text.head()

"""#### Model training

1.9) Create bag of words features for each tweet in the development dataset
"""

#code here
from sklearn.feature_extraction.text import CountVectorizer
vector = CountVectorizer()
dev_text_bow = vector.fit_transform(dev_text['review'])
test_text_bow = vector.transform(test_text['review'])
dev_text_bow

vector.get_feature_names_out()[:50]

"""1.10) Train a supervised learning model of choice on the development dataset"""

#code here
from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression()
log_reg.fit(dev_text_bow, dev_y)

"""1.11) Create TF-IDF features for each tweet in the development dataset"""

from sklearn.feature_extraction.text import TfidfVectorizer
#code here
tfidf_vector = TfidfVectorizer()
dev_text_tfidf = tfidf_vector.fit_transform(dev_text['review'])
test_text_tfidf = tfidf_vector.transform(test_text['review'])

"""1.12) Train the same supervised learning algorithm on the development dataset with TF-IDF features"""

#code here
log_reg_tfidf = LogisticRegression()
log_reg_tfidf.fit(dev_text_tfidf, dev_y)

"""1.13) Compare the performance of the two models on the test dataset"""

#code here
print('----Logistic Regression Test Mean Accuracy----')
print('Bag of Words: ' + str(log_reg.score(test_text_bow, test_y)))
print('TFIDF: ' + str(log_reg_tfidf.score(test_text_tfidf, test_y)))